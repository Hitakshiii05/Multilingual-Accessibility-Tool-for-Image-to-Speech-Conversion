{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aeqQOjqEfkG",
        "outputId": "4f6edb39-5444-4253-882e-2703fdbac0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y tesseract-ocr tesseract-ocr-eng tesseract-ocr-hin tesseract-ocr-guj tesseract-ocr-pan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylhgHJ0WFiZb",
        "outputId": "e3aa713e-32e4-4fcd-b8aa-1a97af16300a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "tesseract-ocr-eng set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-guj tesseract-ocr-hin tesseract-ocr-pan\n",
            "0 upgraded, 3 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 1,895 kB of archives.\n",
            "After this operation, 3,084 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-guj all 1:4.00~git30-7274cfa-1.1 [660 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-hin all 1:4.00~git30-7274cfa-1.1 [913 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-pan all 1:4.00~git30-7274cfa-1.1 [322 kB]\n",
            "Fetched 1,895 kB in 1s (2,729 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-guj.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-guj_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-guj (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-hin.\n",
            "Preparing to unpack .../tesseract-ocr-hin_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-hin (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-pan.\n",
            "Preparing to unpack .../tesseract-ocr-pan_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-pan (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-guj (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-pan (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-hin (1:4.00~git30-7274cfa-1.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytesseract Pillow anuvaad-rev gTTS gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pADsIdYzFn0d",
        "outputId": "3673ae06-9431-4496-9754-b165a58bce53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract"
      ],
      "metadata": {
        "id": "pvtA5ApiFtZS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "giH7rR1HFwju"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "L_ySpH6nF3Em"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from anuvaad_rev import IndicTranslator"
      ],
      "metadata": {
        "id": "peM1Y_QUF4I8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS"
      ],
      "metadata": {
        "id": "J-1LzRHfF7oq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "QFAS7efNF9HO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile"
      ],
      "metadata": {
        "id": "_qFRLtd9F_6y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "8h3yP6ztGBVA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = r\"/usr/bin/tesseract\""
      ],
      "metadata": {
        "id": "lggQmkksGDsS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OCR_LANGS = {\n",
        "    \"English\": \"eng\",\n",
        "    \"Hindi\": \"hin\",\n",
        "    \"Gujarati\": \"guj\",\n",
        "    \"Punjabi\": \"pan\",\n",
        "}"
      ],
      "metadata": {
        "id": "KuhLjSe9GFCP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSLATE_LANGS = {\n",
        "    \"English\": \"en\",\n",
        "    \"Hindi\": \"hi\",\n",
        "    \"Gujarati\": \"gu\",\n",
        "    \"Punjabi\": \"pa\",\n",
        "}"
      ],
      "metadata": {
        "id": "s24uaTlYGHSx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TTS_LANGS = {\n",
        "    \"English\": \"en\",\n",
        "    \"Hindi\": \"hi\",\n",
        "    \"Gujarati\": \"gu\",\n",
        "}"
      ],
      "metadata": {
        "id": "kIE7gWW7GJkm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = IndicTranslator()"
      ],
      "metadata": {
        "id": "J-3X8u3OGLph"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ocr_image(pil_img, ocr_lang_name):\n",
        "    \"\"\"\n",
        "    pil_img: PIL.Image\n",
        "    ocr_lang_name: one of OCR_LANGS keys\n",
        "    \"\"\"\n",
        "    tess_lang = OCR_LANGS.get(ocr_lang_name, \"eng\")\n",
        "    text = pytesseract.image_to_string(pil_img, lang=tess_lang)\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "PQSP42pQGP1l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(text, target_lang_name):\n",
        "    \"\"\"\n",
        "    Uses IndicTrans2 API via anuvaad-rev.\n",
        "    Auto-detects source language; we only specify target.\n",
        "    \"\"\"\n",
        "    if not text or not text.strip():\n",
        "        return \"\"\n",
        "    target_code = TRANSLATE_LANGS.get(target_lang_name, \"en\")\n",
        "    try:\n",
        "        out = translator.translate(text, target_lang=target_code)\n",
        "        return out if out is not None else \"\"\n",
        "    except Exception as e:\n",
        "        print(\"Translation error:\", e)\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "OOdMPmQNGQ4x"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(text, speech_lang_name):\n",
        "    \"\"\"\n",
        "    Uses gTTS to generate speech audio file.\n",
        "    Returns path to a temporary .mp3 or None.\n",
        "    \"\"\"\n",
        "    if not text or not text.strip():\n",
        "        return None\n",
        "\n",
        "    if speech_lang_name not in TTS_LANGS:\n",
        "        # Punjabi is not supported in gTTS: return None and handle in UI\n",
        "        return None\n",
        "\n",
        "    lang_code = TTS_LANGS[speech_lang_name]\n",
        "\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
        "            tts = gTTS(text=text, lang=lang_code)\n",
        "            tts.save(fp.name)\n",
        "            audio_path = fp.name\n",
        "        return audio_path\n",
        "    except Exception as e:\n",
        "        print(\"TTS error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "CYHvh532GTx7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Cell 4: Gradio app for end-to-end pipeline ======\n",
        "\n",
        "def full_pipeline(img, ocr_lang_name, target_lang_name, speak_language_same_as_target=True):\n",
        "    if img is None:\n",
        "        return \"Please upload an image.\", \"\", None, \"No audio generated.\"\n",
        "\n",
        "    pil_img = Image.fromarray(img.astype(\"uint8\")).convert(\"RGB\")\n",
        "\n",
        "    # Step 1: OCR\n",
        "    detected_text = ocr_image(pil_img, ocr_lang_name)\n",
        "    if not detected_text.strip():\n",
        "        return \"No text detected.\", \"\", None, \"No audio generated.\"\n",
        "\n",
        "    # Step 2: Translation\n",
        "    translated_text = translate_text(detected_text, target_lang_name)\n",
        "    if not translated_text.strip():\n",
        "        translated_text = \"(Translation failed – showing original text only)\\n\\n\" + detected_text\n",
        "\n",
        "    # Step 3: TTS\n",
        "    speech_lang_name = target_lang_name if speak_language_same_as_target else \"English\"\n",
        "    audio_path = text_to_speech(translated_text, speech_lang_name)\n",
        "\n",
        "    if speech_lang_name not in TTS_LANGS:\n",
        "        msg = \"Punjabi TTS is not supported in gTTS. You can still see the translated text.\"\n",
        "    elif audio_path is None:\n",
        "        msg = \"Could not generate audio. Check internet connection or text length.\"\n",
        "    else:\n",
        "        msg = f\"Audio generated in {speech_lang_name}.\"\n",
        "\n",
        "    return detected_text, translated_text, audio_path, msg\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Multilingual Image → Text → Speech (Hindi / Gujarati / Punjabi / English)\")\n",
        "    gr.Markdown(\n",
        "        \"Upload an image containing text (medicine label, board, sign, etc.). \"\n",
        "        \"The system will run OCR, translate it, and speak it out.\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        img_input = gr.Image(type=\"numpy\", label=\"Input Image\")\n",
        "\n",
        "        with gr.Column():\n",
        "            ocr_lang = gr.Dropdown(\n",
        "                choices=list(OCR_LANGS.keys()),\n",
        "                value=\"English\",\n",
        "                label=\"OCR language (script of text in image)\",\n",
        "            )\n",
        "\n",
        "            target_lang = gr.Dropdown(\n",
        "                choices=list(TRANSLATE_LANGS.keys()),\n",
        "                value=\"Hindi\",\n",
        "                label=\"Target language for translation\",\n",
        "            )\n",
        "\n",
        "            speak_same = gr.Checkbox(\n",
        "                value=True,\n",
        "                label=\"Speak in the target language\",\n",
        "            )\n",
        "\n",
        "            btn = gr.Button(\"Run\")\n",
        "\n",
        "    with gr.Row():\n",
        "        detected_box = gr.Textbox(\n",
        "            label=\"Detected text (before translation)\",\n",
        "            lines=6,\n",
        "        )\n",
        "        translated_box = gr.Textbox(\n",
        "            label=\"Translated text (for user)\",\n",
        "            lines=6,\n",
        "        )\n",
        "\n",
        "    audio_out = gr.Audio(\n",
        "        label=\"Spoken Output\",\n",
        "        type=\"filepath\",\n",
        "    )\n",
        "    status_box = gr.Textbox(\n",
        "        label=\"Status / Notes\",\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=full_pipeline,\n",
        "        inputs=[img_input, ocr_lang, target_lang, speak_same],\n",
        "        outputs=[detected_box, translated_box, audio_out, status_box],\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "7hckqghXHCAt",
        "outputId": "770c2cc1-0300-4644-a192-6fe4a347ac7b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0cb1b7d1aefb6a05b3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0cb1b7d1aefb6a05b3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}